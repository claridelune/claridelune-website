---
title: 'Dia 10: k-Nearest Neighbors'
description: 'Hoy vi teoría y aplicación del algoritmo k-Nearest Neighbors para clasificar puntos en un gráfico. Hice implementación desde cero, la única librería externa que use fue Matplotlib'
pubDate: '20230730'
tags:
    - python
    - matplotlib
    - 100DaysOfCode
---

La mayor parte básica de teoría lo saque de la pagina web de `IBM`, es como una manera general de entenderlo y suficiente para saber cuando aplicarlo.

Te deja este pequeño código de como sería en python, con scikit-learn es muy fácil aplicarlo.

```python
from sklearn.neighbors import KNeighborsClassifier  
model_name = ‘K-Nearest Neighbor Classifier’  
knnClassifier = KNeighborsClassifier(n_neighbors = 5, metric = ‘minkowski’, p=2)  
knn_model = Pipeline(steps=[(‘preprocessor’, preprocessorForFeatures), (‘classifier’ , knnClassifier)])  
knn_model.fit(X_train, y_train)  
y_pred = knn_model.predict(X_test)
```

Así que el que yo decidí aplicar fue desde cero.

En esta imagen de una parte de mi código se puede ver más o menos cómo funciona:
![codigo-knn](https://pbs.twimg.com/media/F2VvtIQWYAUFLxv?format=jpg&name=medium)

En el input del programa tienes cuanta data quieres tener y dar k, k es con cuantos neighbors quieres chequear para determinar la clasificación de un punto.

La data se genera de esta forma:

![data](https://pbs.twimg.com/media/F2VvvjeXcAAVMS9?format=png&name=medium)
El punto rojo es el que se clasifica, sale true si pertenece al conjunto azul.

Aprendí lo básico creo yo, he encontrado papers que se adentran más en este tema, que si en algún proyecto tengo que aplicar lo chequeare, pero por ahora creo que estoy bien con esto.

## Referencias

- [K-Nearest Neighbors Algorithm - IBM](https://www.ibm.com/topics/knn)